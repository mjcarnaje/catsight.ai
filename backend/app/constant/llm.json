[
  {
    "code": "llama3.1:8b",
    "name": "Llama 3.1 8B",
    "description": "Llama 3.1 8B is a compact general purpose language model optimized for efficiency. It offers good performance for its size, making it suitable for a wide range of applications. This model provides a balance between speed and capability for daily tasks.",
    "logo": "https://avatars.githubusercontent.com/u/69631?s=200&v=4"
  },
  {
    "code": "llama3.2:1b",
    "name": "Llama 3.2 1B",
    "description": "Llama 3.2 1B is a compact general purpose language model optimized for efficiency. It offers good performance for its size, making it suitable for a wide range of applications. This model provides a balance between speed and capability for daily tasks.",
    "logo": "https://avatars.githubusercontent.com/u/69631?s=200&v=4"
  },
  {
    "code": "qwen3:1.7b",
    "name": "Qwen 3.1.7B",
    "description": "Qwen 3 is the latest generation of large language models in Qwen series, offering a comprehensive suite of dense and mixture-of-experts (MoE) models. The flagship model, Qwen3-235B-A22B, achieves competitive results in benchmark evaluations of coding, math, general capabilities, etc., when compared to other top-tier models such as DeepSeek-R1, o1, o3-mini, Grok-3, and Gemini-2.5-Pro. Additionally, the small MoE model offers excellent performance for efficient deployment.",
    "logo": "https://avatars.githubusercontent.com/u/141221163?s=200&v=4"
  },
  {
    "code": "phi4:latest",
    "name": "Phi4",
    "description": "Phi4 is Microsoft's latest small language model, designed for performance and efficiency. It delivers powerful reasoning and coding capabilities while requiring less computational resources than larger models. Phi4 represents a significant advancement in the capabilities of small foundation models, providing an excellent balance between performance and deployment efficiency.",
    "logo": "https://avatars.githubusercontent.com/u/6154722?s=200&v=4"
  }
]
