[
  {
    "code": "llama3.1:8b",
    "name": "Llama 3.1 8B",
    "description": "Meta's Llama 3.1 8B is a compact yet powerful language model that balances performance and efficiency. It offers strong reasoning capabilities and good context handling in a smaller footprint, making it ideal for resource-constrained environments while maintaining quality outputs for various applications.",
    "logo": "https://avatars.githubusercontent.com/u/69631?s=200&v=4",
    "instruct": false
  },
  {
    "code": "llama3.2:1b",
    "name": "Llama 3.2 1B",
    "description": "Meta's Llama 3.2 1B is an ultra-lightweight model designed for edge deployment. Despite its small size, it delivers impressive performance for basic text generation, summarization, and simple reasoning tasks, making it perfect for applications requiring minimal resource consumption.",
    "logo": "https://avatars.githubusercontent.com/u/69631?s=200&v=4",
    "instruct": false
  },
  {
    "code": "qwen3:1.7b",
    "name": "Qwen 3 1.7B",
    "description": "Alibaba's Qwen 3 1.7B model offers remarkable capabilities in a compact size. It excels at multilingual content generation, reasoning, and knowledge tasks while requiring minimal computational resources. This model represents an excellent balance of efficiency and performance for everyday applications.",
    "logo": "https://avatars.githubusercontent.com/u/141221163?s=200&v=4",
    "instruct": false
  },
  {
    "code": "qwen2.5:7b-instruct-q4_K_M",
    "name": "Qwen 2.5 7B Instruct",
    "description": "The instruction-tuned Qwen 2.5 7B model is optimized for following directions and completing specific tasks. Quantized for efficiency (Q4_K_M), it maintains high performance while reducing resource requirements. This model excels at structured responses, creative content generation, and detailed explanations across multiple domains.",
    "logo": "https://avatars.githubusercontent.com/u/141221163?s=200&v=4",
    "instruct": true
  }
]
