{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import asyncio\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from asgiref.sync import sync_to_async\n",
    "from IPython.display import display\n",
    "\n",
    "# If running in a Jupyter environment, allow nested event loops\n",
    "try:\n",
    "    import nest_asyncio\n",
    "    nest_asyncio.apply()\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "# Django setup\n",
    "notebook_dir = Path().absolute()\n",
    "sys.path.insert(0, str(notebook_dir))\n",
    "if 'DJANGO_SETTINGS_MODULE' in os.environ:\n",
    "    del os.environ['DJANGO_SETTINGS_MODULE']\n",
    "os.environ['DJANGO_SETTINGS_MODULE'] = 'inteldocs.settings'\n",
    "import django\n",
    "django.setup()\n",
    "\n",
    "from app.services.vectorstore import vector_store\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMListwiseRerank\n",
    "from langchain_ollama import ChatOllama\n",
    "from app.models import Document\n",
    "\n",
    "# # Ensure full titles are shown and no wrapping\n",
    "# pd.set_option('display.max_colwidth', None)\n",
    "# pd.set_option('display.expand_frame_repr', False)\n",
    "# pd.set_option('display.width', None)\n",
    "\n",
    "# async def get_title(doc_id):\n",
    "#     try:\n",
    "#         d = await sync_to_async(Document.objects.get, thread_sensitive=False)(id=doc_id)\n",
    "#         return d.title\n",
    "#     except Document.DoesNotExist:\n",
    "#         return None\n",
    "\n",
    "# async def process_query(q, top_k, score_threshold, llm_compressor, base_store):\n",
    "#     # 1) Original—pull top_k with scores\n",
    "#     orig_pairs = base_store.similarity_search_with_score(q, k=top_k)\n",
    "#     # 2) Threshold—filter those by score\n",
    "#     thresh_pairs = [(doc, score) for doc, score in orig_pairs if score >= score_threshold]\n",
    "#     # 3) Compressed—just docs, no scores\n",
    "#     compressed_docs = llm_compressor.invoke(q)\n",
    "\n",
    "#     # Map doc_id and chunk_index to score for retrieving compressed scores\n",
    "#     score_map = {\n",
    "#         (doc.metadata.get(\"doc_id\"), doc.metadata.get(\"index\")): score\n",
    "#         for doc, score in orig_pairs\n",
    "#     }\n",
    "\n",
    "#     # Counts for bar chart\n",
    "#     counts = {\n",
    "#         f\"Original (k={top_k})\": len(orig_pairs),\n",
    "#         f\"Threshold (≥{score_threshold})\": len(thresh_pairs),\n",
    "#         \"Compressed (LLM)\": len(compressed_docs),\n",
    "#     }\n",
    "\n",
    "#     # Build flat records list\n",
    "#     records = []\n",
    "#     for name, entries in [\n",
    "#         (f\"Original (k={top_k})\", orig_pairs),\n",
    "#         (f\"Threshold (≥{score_threshold})\", thresh_pairs),\n",
    "#     ]:\n",
    "#         for doc, score in entries:\n",
    "#             title = await get_title(doc.metadata.get(\"doc_id\"))\n",
    "#             records.append({\n",
    "#                 \"Retriever\": name,\n",
    "#                 \"Title\": title,\n",
    "#                 \"Chunk Index\": doc.metadata.get(\"index\"),\n",
    "#                 \"Score\": score,\n",
    "#             })\n",
    "#     for doc in compressed_docs:\n",
    "#         doc_id = doc.metadata.get(\"doc_id\")\n",
    "#         chunk_index = doc.metadata.get(\"index\")\n",
    "#         title = await get_title(doc_id)\n",
    "#         score = score_map.get((doc_id, chunk_index))\n",
    "#         records.append({\n",
    "#             \"Retriever\": \"Compressed (LLM)\",\n",
    "#             \"Title\": title,\n",
    "#             \"Chunk Index\": chunk_index,\n",
    "#             \"Score\": score if score is not None else None,\n",
    "#         })\n",
    "\n",
    "#     # Build DataFrame and MultiIndex\n",
    "#     df = pd.DataFrame(records)\n",
    "#     df = df.sort_values(['Retriever','Score'], ascending=[True, False])\n",
    "#     df_multi = df.set_index(['Retriever','Title','Chunk Index']).sort_index()\n",
    "\n",
    "#     # Print each section in custom order, sorting by score\n",
    "#     print(f\"\\nResults for query: {q}\\n\")\n",
    "#     order = [\n",
    "#         \"Compressed (LLM)\",\n",
    "#         f\"Threshold (≥{score_threshold})\",\n",
    "#         f\"Original (k={top_k})\"\n",
    "#     ]\n",
    "#     for name in order:\n",
    "#         print(f\"{name}:\")\n",
    "#         try:\n",
    "#             section = df_multi.loc[name]\n",
    "#             section_df = section.reset_index()\n",
    "#             # Sort by Score descending, None last\n",
    "#             section_df['Score'] = pd.to_numeric(section_df['Score'], errors='coerce')\n",
    "#             section_df = section_df.sort_values('Score', ascending=False, na_position='last')\n",
    "#             # Render at 100% width in Jupyter\n",
    "#             styled = section_df.style.set_table_attributes('style=\"width:100%;\"')\n",
    "#             display(styled)\n",
    "#         except KeyError:\n",
    "#             print(\"  (no results)\\n\")\n",
    "\n",
    "#     # Bar chart\n",
    "#     plt.figure(figsize=(6, 3))\n",
    "#     plt.bar(counts.keys(), counts.values())\n",
    "#     plt.ylabel(\"Num Docs\")\n",
    "#     plt.title(f\"Docs Retrieved for “{q}”\")\n",
    "#     plt.xticks(rotation=25, ha=\"right\")\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "# async def main():\n",
    "#     TOP_K = 10\n",
    "#     SCORE_THRESHOLD = 0.4\n",
    "\n",
    "#     llm = ChatOllama(model=\"llama3.1:8b\", base_url=\"http://ollama:11434\", temperature=0)\n",
    "#     compressor = LLMListwiseRerank.from_llm(llm)\n",
    "#     score_retriever = vector_store.as_retriever(\n",
    "#         search_type=\"similarity_score_threshold\",\n",
    "#         search_kwargs={\"score_threshold\": SCORE_THRESHOLD}\n",
    "#     )\n",
    "#     compression_retriever = ContextualCompressionRetriever(\n",
    "#         base_compressor=compressor,\n",
    "#         base_retriever=score_retriever\n",
    "#     )\n",
    "\n",
    "#     queries = [\n",
    "#         \"Who is Requina?\"\n",
    "#     ]\n",
    "#     for q in queries:\n",
    "#         await process_query(q, TOP_K, SCORE_THRESHOLD, compression_retriever, vector_store)\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     try:\n",
    "#         asyncio.run(main())\n",
    "#     except RuntimeError:\n",
    "#         loop = asyncio.get_event_loop()\n",
    "#         loop.run_until_complete(main())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.services.catsight_agent import catsight_agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(AIMessageChunk(content='Since there\\'s no specific query related to MSU-IIT policies or processes, I will respond with a prompt asking for clarification instead of providing a function call. However, following your format as closely as possible:\\n\\n> *\"I don\\'t have enough information to answer that question completely.\"*', additional_kwargs={}, response_metadata={'model': 'llama3.1:8b', 'created_at': '2025-05-19T15:08:47.946563012Z', 'done': True, 'done_reason': 'stop', 'total_duration': 35191237034, 'load_duration': 15159268, 'prompt_eval_count': 957, 'prompt_eval_duration': 3822267403, 'eval_count': 58, 'eval_duration': 31347189898, 'model_name': 'llama3.1:8b'}, id='run--b425d93a-79b4-4b33-bcf3-b41e9c0cb44f', usage_metadata={'input_tokens': 957, 'output_tokens': 58, 'total_tokens': 1015}), {'model': 'llama3.1:8b', 'thread_id': '1', 'langgraph_step': 5, 'langgraph_node': 'assistant', 'langgraph_triggers': ('branch:to:assistant',), 'langgraph_path': ('__pregel_pull', 'assistant'), 'langgraph_checkpoint_ns': 'assistant:1f9b97b9-7a63-f5e6-dda6-fa1b4dbf3ff7', 'checkpoint_ns': 'assistant:1f9b97b9-7a63-f5e6-dda6-fa1b4dbf3ff7', 'ls_provider': 'ollama', 'ls_model_name': 'llama3.1:8b', 'ls_model_type': 'chat', 'ls_temperature': 1.0})\n",
      "(AIMessageChunk(content='{\"', additional_kwargs={}, response_metadata={}, id='run--f58c62e4-a1f7-4e87-8cf7-9186ef295f47'), {'model': 'llama3.1:8b', 'thread_id': '1', 'langgraph_step': 6, 'langgraph_node': 'generate_title', 'langgraph_triggers': ('branch:to:generate_title',), 'langgraph_path': ('__pregel_pull', 'generate_title'), 'langgraph_checkpoint_ns': 'generate_title:b2a432dd-609a-5cf4-a2fa-5bd3cd47e024', 'checkpoint_ns': 'generate_title:b2a432dd-609a-5cf4-a2fa-5bd3cd47e024', 'ls_provider': 'ollama', 'ls_model_name': 'llama3.2:1b', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content='title', additional_kwargs={}, response_metadata={}, id='run--f58c62e4-a1f7-4e87-8cf7-9186ef295f47'), {'model': 'llama3.1:8b', 'thread_id': '1', 'langgraph_step': 6, 'langgraph_node': 'generate_title', 'langgraph_triggers': ('branch:to:generate_title',), 'langgraph_path': ('__pregel_pull', 'generate_title'), 'langgraph_checkpoint_ns': 'generate_title:b2a432dd-609a-5cf4-a2fa-5bd3cd47e024', 'checkpoint_ns': 'generate_title:b2a432dd-609a-5cf4-a2fa-5bd3cd47e024', 'ls_provider': 'ollama', 'ls_model_name': 'llama3.2:1b', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content='\":', additional_kwargs={}, response_metadata={}, id='run--f58c62e4-a1f7-4e87-8cf7-9186ef295f47'), {'model': 'llama3.1:8b', 'thread_id': '1', 'langgraph_step': 6, 'langgraph_node': 'generate_title', 'langgraph_triggers': ('branch:to:generate_title',), 'langgraph_path': ('__pregel_pull', 'generate_title'), 'langgraph_checkpoint_ns': 'generate_title:b2a432dd-609a-5cf4-a2fa-5bd3cd47e024', 'checkpoint_ns': 'generate_title:b2a432dd-609a-5cf4-a2fa-5bd3cd47e024', 'ls_provider': 'ollama', 'ls_model_name': 'llama3.2:1b', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content=' \"', additional_kwargs={}, response_metadata={}, id='run--f58c62e4-a1f7-4e87-8cf7-9186ef295f47'), {'model': 'llama3.1:8b', 'thread_id': '1', 'langgraph_step': 6, 'langgraph_node': 'generate_title', 'langgraph_triggers': ('branch:to:generate_title',), 'langgraph_path': ('__pregel_pull', 'generate_title'), 'langgraph_checkpoint_ns': 'generate_title:b2a432dd-609a-5cf4-a2fa-5bd3cd47e024', 'checkpoint_ns': 'generate_title:b2a432dd-609a-5cf4-a2fa-5bd3cd47e024', 'ls_provider': 'ollama', 'ls_model_name': 'llama3.2:1b', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content='T', additional_kwargs={}, response_metadata={}, id='run--f58c62e4-a1f7-4e87-8cf7-9186ef295f47'), {'model': 'llama3.1:8b', 'thread_id': '1', 'langgraph_step': 6, 'langgraph_node': 'generate_title', 'langgraph_triggers': ('branch:to:generate_title',), 'langgraph_path': ('__pregel_pull', 'generate_title'), 'langgraph_checkpoint_ns': 'generate_title:b2a432dd-609a-5cf4-a2fa-5bd3cd47e024', 'checkpoint_ns': 'generate_title:b2a432dd-609a-5cf4-a2fa-5bd3cd47e024', 'ls_provider': 'ollama', 'ls_model_name': 'llama3.2:1b', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content='uition', additional_kwargs={}, response_metadata={}, id='run--f58c62e4-a1f7-4e87-8cf7-9186ef295f47'), {'model': 'llama3.1:8b', 'thread_id': '1', 'langgraph_step': 6, 'langgraph_node': 'generate_title', 'langgraph_triggers': ('branch:to:generate_title',), 'langgraph_path': ('__pregel_pull', 'generate_title'), 'langgraph_checkpoint_ns': 'generate_title:b2a432dd-609a-5cf4-a2fa-5bd3cd47e024', 'checkpoint_ns': 'generate_title:b2a432dd-609a-5cf4-a2fa-5bd3cd47e024', 'ls_provider': 'ollama', 'ls_model_name': 'llama3.2:1b', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content=' Ref', additional_kwargs={}, response_metadata={}, id='run--f58c62e4-a1f7-4e87-8cf7-9186ef295f47'), {'model': 'llama3.1:8b', 'thread_id': '1', 'langgraph_step': 6, 'langgraph_node': 'generate_title', 'langgraph_triggers': ('branch:to:generate_title',), 'langgraph_path': ('__pregel_pull', 'generate_title'), 'langgraph_checkpoint_ns': 'generate_title:b2a432dd-609a-5cf4-a2fa-5bd3cd47e024', 'checkpoint_ns': 'generate_title:b2a432dd-609a-5cf4-a2fa-5bd3cd47e024', 'ls_provider': 'ollama', 'ls_model_name': 'llama3.2:1b', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content='und', additional_kwargs={}, response_metadata={}, id='run--f58c62e4-a1f7-4e87-8cf7-9186ef295f47'), {'model': 'llama3.1:8b', 'thread_id': '1', 'langgraph_step': 6, 'langgraph_node': 'generate_title', 'langgraph_triggers': ('branch:to:generate_title',), 'langgraph_path': ('__pregel_pull', 'generate_title'), 'langgraph_checkpoint_ns': 'generate_title:b2a432dd-609a-5cf4-a2fa-5bd3cd47e024', 'checkpoint_ns': 'generate_title:b2a432dd-609a-5cf4-a2fa-5bd3cd47e024', 'ls_provider': 'ollama', 'ls_model_name': 'llama3.2:1b', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content=' Dead', additional_kwargs={}, response_metadata={}, id='run--f58c62e4-a1f7-4e87-8cf7-9186ef295f47'), {'model': 'llama3.1:8b', 'thread_id': '1', 'langgraph_step': 6, 'langgraph_node': 'generate_title', 'langgraph_triggers': ('branch:to:generate_title',), 'langgraph_path': ('__pregel_pull', 'generate_title'), 'langgraph_checkpoint_ns': 'generate_title:b2a432dd-609a-5cf4-a2fa-5bd3cd47e024', 'checkpoint_ns': 'generate_title:b2a432dd-609a-5cf4-a2fa-5bd3cd47e024', 'ls_provider': 'ollama', 'ls_model_name': 'llama3.2:1b', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content='lines', additional_kwargs={}, response_metadata={}, id='run--f58c62e4-a1f7-4e87-8cf7-9186ef295f47'), {'model': 'llama3.1:8b', 'thread_id': '1', 'langgraph_step': 6, 'langgraph_node': 'generate_title', 'langgraph_triggers': ('branch:to:generate_title',), 'langgraph_path': ('__pregel_pull', 'generate_title'), 'langgraph_checkpoint_ns': 'generate_title:b2a432dd-609a-5cf4-a2fa-5bd3cd47e024', 'checkpoint_ns': 'generate_title:b2a432dd-609a-5cf4-a2fa-5bd3cd47e024', 'ls_provider': 'ollama', 'ls_model_name': 'llama3.2:1b', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content=' Expl', additional_kwargs={}, response_metadata={}, id='run--f58c62e4-a1f7-4e87-8cf7-9186ef295f47'), {'model': 'llama3.1:8b', 'thread_id': '1', 'langgraph_step': 6, 'langgraph_node': 'generate_title', 'langgraph_triggers': ('branch:to:generate_title',), 'langgraph_path': ('__pregel_pull', 'generate_title'), 'langgraph_checkpoint_ns': 'generate_title:b2a432dd-609a-5cf4-a2fa-5bd3cd47e024', 'checkpoint_ns': 'generate_title:b2a432dd-609a-5cf4-a2fa-5bd3cd47e024', 'ls_provider': 'ollama', 'ls_model_name': 'llama3.2:1b', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content='ained', additional_kwargs={}, response_metadata={}, id='run--f58c62e4-a1f7-4e87-8cf7-9186ef295f47'), {'model': 'llama3.1:8b', 'thread_id': '1', 'langgraph_step': 6, 'langgraph_node': 'generate_title', 'langgraph_triggers': ('branch:to:generate_title',), 'langgraph_path': ('__pregel_pull', 'generate_title'), 'langgraph_checkpoint_ns': 'generate_title:b2a432dd-609a-5cf4-a2fa-5bd3cd47e024', 'checkpoint_ns': 'generate_title:b2a432dd-609a-5cf4-a2fa-5bd3cd47e024', 'ls_provider': 'ollama', 'ls_model_name': 'llama3.2:1b', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content='\"', additional_kwargs={}, response_metadata={}, id='run--f58c62e4-a1f7-4e87-8cf7-9186ef295f47'), {'model': 'llama3.1:8b', 'thread_id': '1', 'langgraph_step': 6, 'langgraph_node': 'generate_title', 'langgraph_triggers': ('branch:to:generate_title',), 'langgraph_path': ('__pregel_pull', 'generate_title'), 'langgraph_checkpoint_ns': 'generate_title:b2a432dd-609a-5cf4-a2fa-5bd3cd47e024', 'checkpoint_ns': 'generate_title:b2a432dd-609a-5cf4-a2fa-5bd3cd47e024', 'ls_provider': 'ollama', 'ls_model_name': 'llama3.2:1b', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO 2025-05-19 15:08:57,940 catsight_agent 39 139963609884352 Generated title: Tuition Refund Deadlines Explained\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(AIMessageChunk(content='}', additional_kwargs={}, response_metadata={}, id='run--f58c62e4-a1f7-4e87-8cf7-9186ef295f47'), {'model': 'llama3.1:8b', 'thread_id': '1', 'langgraph_step': 6, 'langgraph_node': 'generate_title', 'langgraph_triggers': ('branch:to:generate_title',), 'langgraph_path': ('__pregel_pull', 'generate_title'), 'langgraph_checkpoint_ns': 'generate_title:b2a432dd-609a-5cf4-a2fa-5bd3cd47e024', 'checkpoint_ns': 'generate_title:b2a432dd-609a-5cf4-a2fa-5bd3cd47e024', 'ls_provider': 'ollama', 'ls_model_name': 'llama3.2:1b', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n",
      "(AIMessageChunk(content='', additional_kwargs={}, response_metadata={'model': 'llama3.2:1b', 'created_at': '2025-05-19T15:08:57.937901124Z', 'done': True, 'done_reason': 'stop', 'total_duration': 9944606655, 'load_duration': 9372651097, 'prompt_eval_count': 224, 'prompt_eval_duration': 314199211, 'eval_count': 15, 'eval_duration': 254640516, 'model_name': 'llama3.2:1b'}, id='run--f58c62e4-a1f7-4e87-8cf7-9186ef295f47', usage_metadata={'input_tokens': 224, 'output_tokens': 15, 'total_tokens': 239}), {'model': 'llama3.1:8b', 'thread_id': '1', 'langgraph_step': 6, 'langgraph_node': 'generate_title', 'langgraph_triggers': ('branch:to:generate_title',), 'langgraph_path': ('__pregel_pull', 'generate_title'), 'langgraph_checkpoint_ns': 'generate_title:b2a432dd-609a-5cf4-a2fa-5bd3cd47e024', 'checkpoint_ns': 'generate_title:b2a432dd-609a-5cf4-a2fa-5bd3cd47e024', 'ls_provider': 'ollama', 'ls_model_name': 'llama3.2:1b', 'ls_model_type': 'chat', 'ls_temperature': 0.0})\n"
     ]
    }
   ],
   "source": [
    "for chunk in catsight_agent.stream(\n",
    "    input={\"current_query\": \"Who is Dante Dinawanao?\", \"messages\": [\"Who is Dante Dinawanao?\"], \"file_ids\": []},\n",
    "    config={\"configurable\": {\"model\": \"llama3.1:8b\", \"thread_id\": \"1\"}},\n",
    "    stream_mode=\"messages\"\n",
    "):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
